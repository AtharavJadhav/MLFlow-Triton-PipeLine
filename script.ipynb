{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atharav/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import mlflow.onnx\n",
    "import onnx\n",
    "import onnxruntime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return torch.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loaders\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "train_loader = DataLoader(datasets.MNIST('../data', train=True, download=True, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(datasets.MNIST('../data', train=False, transform=transform), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = Net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    mlflow.set_experiment(\"MNIST_ONNX_Experiment\")\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        mlflow.log_param(\"momentum\", momentum)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if batch_idx % log_interval == 0:\n",
    "                    mlflow.log_metric('loss', loss.item(), step=epoch * len(train_loader) + batch_idx)\n",
    "\n",
    "            # Evaluate on test set\n",
    "            model.eval()\n",
    "            test_loss = 0\n",
    "            correct = 0\n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    output = model(data)\n",
    "                    test_loss += criterion(output, target).item()\n",
    "                    pred = output.argmax(dim=1, keepdim=True)\n",
    "                    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "            accuracy = 100. * correct / len(test_loader.dataset)\n",
    "            mlflow.log_metric('test_loss', test_loss, step=epoch)\n",
    "            mlflow.log_metric('accuracy', accuracy, step=epoch)\n",
    "\n",
    "        # Convert and log the model in ONNX format\n",
    "        dummy_input = torch.randn(1, 1, 28, 28)\n",
    "        torch.onnx.export(model, dummy_input, \"mnist_model.onnx\")\n",
    "        mlflow.onnx.log_model(onnx_model=onnx.load(\"mnist_model.onnx\"), artifact_path=\"mnist_model\")\n",
    "\n",
    "    print('Training complete.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(model):\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    torch.onnx.export(model, dummy_input, \"model.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enable_dynamic_batching():\n",
    "    model = onnx.load(\"model.onnx\")\n",
    "    graph = model.graph\n",
    "    for input_tensor in graph.input:\n",
    "        input_tensor.type.tensor_type.shape.dim[0].dim_param = 'batch_size'\n",
    "    for output_tensor in graph.output:\n",
    "        output_tensor.type.tensor_type.shape.dim[0].dim_param = 'batch_size'\n",
    "    onnx.save(model, \"model_dynamic.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_triton_repository():\n",
    "    os.makedirs(\"model_repository/mnist_model/1\", exist_ok=True)\n",
    "    shutil.move(\"model_dynamic.onnx\", \"model_repository/mnist_model/1/model.onnx\")\n",
    "\n",
    "    input_name, output_name = get_model_io_names(\"model.onnx\")\n",
    "\n",
    "    with open(\"model_repository/mnist_model/config.pbtxt\", \"w\") as f:\n",
    "        f.write(f\"\"\"\n",
    "name: \"mnist_model\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size: 0  # Enable dynamic batching\n",
    "input [\n",
    "  {{\n",
    "    name: \"{input_name}\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1, 1, 28, 28 ]\n",
    "  }}\n",
    "]\n",
    "output [\n",
    "  {{\n",
    "    name: \"{output_name}\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ -1, 10 ]\n",
    "  }}\n",
    "]\n",
    "        \"\"\")\n",
    "\n",
    "def get_model_io_names(onnx_model_path):\n",
    "    model = onnx.load(onnx_model_path)\n",
    "    input_name = model.graph.input[0].name\n",
    "    output_name = model.graph.output[0].name\n",
    "    return input_name, output_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/28 12:39:59 INFO mlflow.tracking.fluent: Experiment with name 'MNIST_ONNX_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "Model training, logging, and Triton deployment preparation complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    trained_model = train_model()\n",
    "    convert_to_onnx(trained_model)\n",
    "    enable_dynamic_batching()\n",
    "    prepare_triton_repository()\n",
    "    print(\"Model training, logging, and Triton deployment preparation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
